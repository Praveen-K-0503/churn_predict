{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChurnGuard Dataset Analysis & Integration\n",
    "## Real Telecom Customer Churn Dataset - 7,043 Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load your telecom dataset\n",
    "df = pd.read_csv(r'D:\\Windows Data\\Downloads\\archive (6)\\WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Overview\n",
    "print(\"=== CHURNGUARD DATASET ANALYSIS ===\")\n",
    "print(f\"Total Customers: {len(df):,}\")\n",
    "print(f\"Features: {len(df.columns)}\")\n",
    "print(f\"Missing Values: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# Churn Distribution\n",
    "churn_dist = df['Churn'].value_counts()\n",
    "churn_rate = (churn_dist['Yes'] / len(df)) * 100\n",
    "print(f\"\\nChurn Rate: {churn_rate:.1f}%\")\n",
    "print(f\"Churned Customers: {churn_dist['Yes']:,}\")\n",
    "print(f\"Retained Customers: {churn_dist['No']:,}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChurnGuard Feature Engineering (Same as Production Pipeline)\n",
    "def churnguard_preprocessing(df):\n",
    "    \"\"\"ChurnGuard production preprocessing pipeline\"\"\"\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Handle TotalCharges (convert to numeric)\n",
    "    df_processed['TotalCharges'] = pd.to_numeric(df_processed['TotalCharges'], errors='coerce')\n",
    "    df_processed['TotalCharges'].fillna(df_processed['MonthlyCharges'], inplace=True)\n",
    "    \n",
    "    # ChurnGuard Feature Engineering\n",
    "    df_processed['tenure_group'] = pd.cut(df_processed['tenure'], bins=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "    df_processed['avg_monthly_charges'] = df_processed['TotalCharges'] / (df_processed['tenure'] + 1)\n",
    "    \n",
    "    # Service count (ChurnGuard metric)\n",
    "    service_cols = ['PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', \n",
    "                   'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "    df_processed['total_services'] = df_processed[service_cols].apply(\n",
    "        lambda x: sum([1 for val in x if val == 'Yes']), axis=1\n",
    "    )\n",
    "    \n",
    "    # Encode target\n",
    "    df_processed['Churn_Binary'] = df_processed['Churn'].map({'Yes': 1, 'No': 0})\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "# Apply ChurnGuard preprocessing\n",
    "df_processed = churnguard_preprocessing(df)\n",
    "print(\"ChurnGuard preprocessing completed!\")\n",
    "print(f\"New features: tenure_group, avg_monthly_charges, total_services\")\n",
    "df_processed[['customerID', 'tenure', 'tenure_group', 'avg_monthly_charges', 'total_services', 'Churn']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChurnGuard Analytics Dashboard Preview\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('ChurnGuard Analytics Dashboard Preview', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Churn Rate by Tenure Group\n",
    "tenure_churn = df_processed.groupby('tenure_group')['Churn_Binary'].mean() * 100\n",
    "tenure_churn.plot(kind='bar', ax=axes[0,0], color='#3B82F6')\n",
    "axes[0,0].set_title('Churn Rate by Tenure Group')\n",
    "axes[0,0].set_ylabel('Churn Rate (%)')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Monthly Charges Distribution\n",
    "df_processed.boxplot(column='MonthlyCharges', by='Churn', ax=axes[0,1])\n",
    "axes[0,1].set_title('Monthly Charges by Churn Status')\n",
    "axes[0,1].set_xlabel('Churn Status')\n",
    "\n",
    "# 3. Contract Type Impact\n",
    "contract_churn = df_processed.groupby('Contract')['Churn_Binary'].mean() * 100\n",
    "contract_churn.plot(kind='bar', ax=axes[1,0], color='#10B981')\n",
    "axes[1,0].set_title('Churn Rate by Contract Type')\n",
    "axes[1,0].set_ylabel('Churn Rate (%)')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Payment Method Impact\n",
    "payment_churn = df_processed.groupby('PaymentMethod')['Churn_Binary'].mean() * 100\n",
    "payment_churn.plot(kind='bar', ax=axes[1,1], color='#F59E0B')\n",
    "axes[1,1].set_title('Churn Rate by Payment Method')\n",
    "axes[1,1].set_ylabel('Churn Rate (%)')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== KEY INSIGHTS FOR CHURNGUARD ===\")\n",
    "print(f\"Highest Risk Tenure: {tenure_churn.idxmax()} ({tenure_churn.max():.1f}% churn rate)\")\n",
    "print(f\"Highest Risk Contract: {contract_churn.idxmax()} ({contract_churn.max():.1f}% churn rate)\")\n",
    "print(f\"Highest Risk Payment: {payment_churn.idxmax()} ({payment_churn.max():.1f}% churn rate)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChurnGuard ML Model Training (Production Pipeline)\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Prepare features for ChurnGuard ML pipeline\n",
    "def prepare_features(df):\n",
    "    \"\"\"ChurnGuard feature preparation\"\"\"\n",
    "    # Select features\n",
    "    feature_cols = ['tenure', 'MonthlyCharges', 'TotalCharges', 'total_services', 'avg_monthly_charges']\n",
    "    categorical_cols = ['gender', 'Partner', 'Dependents', 'PhoneService', 'InternetService', \n",
    "                       'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
    "    \n",
    "    X = df[feature_cols].copy()\n",
    "    \n",
    "    # One-hot encode categorical variables\n",
    "    for col in categorical_cols:\n",
    "        if col in df.columns:\n",
    "            dummies = pd.get_dummies(df[col], prefix=col)\n",
    "            X = pd.concat([X, dummies], axis=1)\n",
    "    \n",
    "    y = df['Churn_Binary']\n",
    "    return X, y\n",
    "\n",
    "# Prepare data\n",
    "X, y = prepare_features(df_processed)\n",
    "print(f\"Features prepared: {X.shape[1]} features, {len(X)} samples\")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Apply SMOTE (ChurnGuard balancing)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_balanced)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set: {len(X_train_scaled)} samples (balanced with SMOTE)\")\n",
    "print(f\"Test set: {len(X_test_scaled)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChurnGuard Multi-Model Training (Production Models)\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "results = {}\n",
    "print(\"=== CHURNGUARD MODEL PERFORMANCE ===\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train model\n",
    "    model.fit(X_train_scaled, y_train_balanced)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Metrics\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    \n",
    "    results[name] = {\n",
    "        'f1_score': report['weighted avg']['f1-score'],\n",
    "        'precision': report['weighted avg']['precision'],\n",
    "        'recall': report['weighted avg']['recall'],\n",
    "        'auc': auc\n",
    "    }\n",
    "    \n",
    "    # Display results\n",
    "    f1_score = results[name]['f1_score'] * 100\n",
    "    auc_score = results[name]['auc'] * 100\n",
    "    print(f\"{name:15} | F1: {f1_score:5.1f}% | AUC: {auc_score:5.1f}%\")\n",
    "\n",
    "# Find best model\n",
    "best_model_name = max(results.keys(), key=lambda k: results[k]['f1_score'])\n",
    "print(f\"\\nðŸ† Best Model: {best_model_name}\")\n",
    "print(f\"F1 Score: {results[best_model_name]['f1_score']:.3f}\")\n",
    "print(f\"AUC Score: {results[best_model_name]['auc']:.3f}\")\n",
    "\n",
    "# Validate ChurnGuard requirements\n",
    "if results[best_model_name]['f1_score'] >= 0.8:\n",
    "    print(\"âœ… Model meets ChurnGuard F1 > 0.8 requirement\")\n",
    "else:\n",
    "    print(\"âš ï¸ Model F1 score below 0.8 threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChurnGuard High-Risk Customer Identification\n",
    "best_model = models[best_model_name]\n",
    "risk_probabilities = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Create risk segments\n",
    "test_customers = X_test.copy()\n",
    "test_customers['risk_score'] = risk_probabilities\n",
    "test_customers['risk_level'] = pd.cut(risk_probabilities, \n",
    "                                     bins=[0, 0.3, 0.7, 1.0], \n",
    "                                     labels=['Low', 'Medium', 'High'])\n",
    "test_customers['actual_churn'] = y_test.values\n",
    "\n",
    "# High-risk customers (ChurnGuard priority list)\n",
    "high_risk = test_customers[test_customers['risk_level'] == 'High'].sort_values('risk_score', ascending=False)\n",
    "\n",
    "print(\"=== CHURNGUARD HIGH-RISK CUSTOMERS ===\")\n",
    "print(f\"Total High-Risk Customers: {len(high_risk)}\")\n",
    "print(f\"Accuracy on High-Risk: {(high_risk['actual_churn'] == 1).mean()*100:.1f}%\")\n",
    "print(\"\\nTop 10 Highest Risk Customers:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for idx, (_, customer) in enumerate(high_risk.head(10).iterrows(), 1):\n",
    "    risk_pct = customer['risk_score'] * 100\n",
    "    actual = \"CHURNED\" if customer['actual_churn'] == 1 else \"RETAINED\"\n",
    "    print(f\"{idx:2d}. Risk: {risk_pct:5.1f}% | Tenure: {customer['tenure']:2.0f} | Charges: ${customer['MonthlyCharges']:5.1f} | {actual}\")\n",
    "\n",
    "# Risk distribution\n",
    "risk_dist = test_customers['risk_level'].value_counts()\n",
    "print(f\"\\nRisk Distribution:\")\n",
    "for level in ['Low', 'Medium', 'High']:\n",
    "    count = risk_dist.get(level, 0)\n",
    "    pct = (count / len(test_customers)) * 100\n",
    "    print(f\"{level:6} Risk: {count:4d} customers ({pct:4.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed dataset for ChurnGuard deployment\n",
    "output_path = r'e:\\churnforgeprediction\\data\\telecom_churn.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"âœ… Dataset saved to ChurnGuard: {output_path}\")\n",
    "print(f\"ðŸ“Š Ready for deployment: {len(df):,} customers, {df['Churn'].value_counts()['Yes']:,} churned\")\n",
    "print(f\"ðŸŽ¯ Expected model performance: F1 > {results[best_model_name]['f1_score']:.1%}\")\n",
    "\n",
    "# ChurnGuard deployment summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸš€ CHURNGUARD DEPLOYMENT READY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dataset: {len(df):,} telecom customers\")\n",
    "print(f\"Features: {len(df.columns)} columns\")\n",
    "print(f\"Churn Rate: {(df['Churn'] == 'Yes').mean()*100:.1f}%\")\n",
    "print(f\"Best Model: {best_model_name} (F1: {results[best_model_name]['f1_score']:.1%})\")\n",
    "print(f\"High-Risk Customers: {len(high_risk)} identified\")\n",
    "print(\"\\nâœ… Ready for AWS deployment with your production credentials!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}